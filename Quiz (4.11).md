## 동건

### 문제1
역전파 알고리즘을 사용하는 이유는?

### 풀이
- 동건: 
- 정우: 
- 현아: 복잡한 문제의 경우 오차 역전파(back propagation)의 방법이 더 효율적이므로 (?)
- 아영:
- 승렬:
- 지원:

### 문제2
f(x) = x^2, g(x) = x+b 일때, x의 변화량에 대한 f(g(x))의 변화량은?

### 풀이
- 동건:
- 정우: 
- 현아: 2x+2
- 아영:
- 승렬:
- 지원:
---
## 정우

### 문제1

### 풀이
- 동건: 
- 정우: 
- 현아: 
- 아영:
- 승렬: 
- 지원:

### 문제2

### 풀이
- 동건:
- 정우: 
- 현아:
- 아영:
- 승렬:
- 지원:
---

## 승렬

### 문제1. 
Find another W and b for the XOR. (lec9-1 11:43 그림 참조)

### 풀이
- 동건: 
- 정우: 
- 현아: 
- 아영:
- 승렬: 
- 지원:

### 문제2

### 풀이
- 동건:
- 정우: 
- 현아:
- 아영:
- 승렬:
- 지원:
---

## 현아

### 문제1
Neural Network가 deep하다 & wide하다는 것의 의미를 각각 서술하시오.

### 풀이
- 동건: 
- 정우: 
- 현아: Wide Neural Network는 중간 layer에서 많은 입력값, 출력값을 활용하여 최종 y 추정값을 구해내는 것. Deep Neural Network는 layer를 많이 쌓는 것.
- 아영:
- 승렬: 
- 지원:

### 문제2
TensorBoard를 사용하는 5가지 단계에 대해 설명하시오.

### 풀이
- 동건:
- 정우: 
- 현아:
- 아영:
- 승렬:
- 지원:
---

## 아영

### 문제1
g=wx, f=g+b이고 δg/δw=3, δf/δg=1일 때 w가 f에 미치는 영향을 값으로 표현하면?

### 풀이
- 동건: 
- 정우: 
- 현아: 3
- 아영:
- 승렬: 
- 지원:

### 문제2
learning rate가 0.1일때와 learning rate가 0.01일때의 그래프를 비교해서 보려고 한다. tensorboard를 사용해 어떻게 그래프를 구현할 수 있을까? (간단히 설명)

### 풀이
- 동건:
- 정우: 
- 현아:
- 아영:
- 승렬:
- 지원:
---

## 지원

### 문제1
하나의 Neural Network를 구성하는 K(X)와 H(X)에 관한 코드를 한 줄씩 작성하시오.

### 풀이
- 동건: 
- 정우: 
- 현아: K(X)는 layer1 = tf.sigmoid(tf.matmul(X, W1) + b1), H(X)는 hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)
- 아영:
- 승렬: 
- 지원:

### 문제2
back propagation을 간략히 서술하시오.

### 풀이
- 동건:
- 정우: 
- 현아: back propagation이란 output에서 input으로의 방향(역방향)으로 오차(error)를 보내며 가중치를 업데이트하는 것을 말한다. (https://sacko.tistory.com/19)
- 아영:
- 승렬:
- 지원:
---
