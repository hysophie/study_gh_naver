## 현아

### 문제1
Vanishing gradient 문제에 대해 설명하고, 이를 해결하는 2가지 방법을 설명하세요. (RBM 개념을 포함해서 설명하세요.)

### 풀이
- 동건: 
- 정우: 
- 현아: 
- 아영:
- 승렬: 
- 지원:

### 문제2
Deep learning에서 layer 개수를 늘릴수록 발생하는 문제와, 이를 해결하는 방법에 대해 설명하세요.

### 풀이
- 동건:
- 정우: 
- 현아:
- 아영:
- 승렬:
- 지원:
---

## 동건

### 문제1

sigmoid와 ReLU 두 함수 식의 차이를 설명하고, 그 차이로 인한 효과를 설명해주세요. 

### 풀이
- 동건: 
- 정우: 
- 현아: 
- 아영:
- 승렬: 
- 지원:

## 승렬

### 문제1.
Gradient descent optimizer가 아닌 다른 optimizer들을 각자 하나씩 조사해보고 간략하게 풀이란에 소개해주자! 풀이란의 순서인 데미안~지원 순으로 ML lab 10 영상 11:50에 있는 Adadelta optimizer부터 Ftrl optimizer까지 하나씩 맡아봅시다!

### 풀이
- 동건: 
- 정우: 
- 현아: 
- 아영:
- 승렬: 
- 지원:

## 정우

### 문제1.
1. dropout이 어떤 방식으로 작동하는 지 설명하시오 2. dropout을 구현할 때 주의할 점을 

### 풀이
- 동건: 
- 정우: 
- 현아: 
- 아영:
- 승렬: 
- 지원:
